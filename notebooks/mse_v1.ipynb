{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import eigh\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "import faiss\n",
    "import json\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = os.getenv(\"K\", 4)\n",
    "NUM_EPOCHS = int(os.getenv(\"NUM_EPOCHS\", 15))\n",
    "\n",
    "PRF_KEY = int(os.getenv(\"PRF_KEY\", 42))\n",
    "LABELING = os.getenv(\"LABELING\", \"kmeans\")\n",
    "ROOT_DIR = os.getenv(\"ROOT_DIR\", \".\")\n",
    "ALIGN = int(os.getenv(\"ALIGN\", 0))\n",
    "output_file = os.getenv(\"OUTPUT_FILE\", None)\n",
    "\n",
    "if ALIGN == 1:\n",
    "    ALIGNMENT_MODEL = \"ridge\"\n",
    "if ALIGN == 2:\n",
    "    ALIGNMENT_MODEL = \"distillation\"\n",
    "\n",
    "\n",
    "model_name = os.getenv(\"MODEL\", \"meta-llama/Llama-2-7b-hf\")\n",
    "\n",
    "assert LABELING in [\"kmeans\", \"rand_proj\"]\n",
    "\n",
    "\n",
    "k = int(k)\n",
    "print(f\"K: {k}, Num epochs: {NUM_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Skylion007/openwebtext\"\n",
    "model_suffix = model_name.split(\"/\")[-1]\n",
    "dataset_suffix = dataset_name.split(\"/\")[-1]\n",
    "dir = f\"{ROOT_DIR}/data/{dataset_suffix}_{model_suffix}\"\n",
    "model_dir = f\"{ROOT_DIR}/saved_models/{dataset_suffix}_{model_suffix}\"\n",
    "hidden_states = torch.load(f\"{dir}/hidden_states.pt\")\n",
    "\n",
    "hidden_states = hidden_states.float()\n",
    "print(f\"Hidden states shape: {hidden_states.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(X, Y, alpha):\n",
    "    d_in = X.shape[1]\n",
    "    I = torch.eye(d_in, device=X.device)\n",
    "    W = torch.linalg.solve(X.T @ X + alpha * I, X.T @ Y)\n",
    "    return W\n",
    "\n",
    "\n",
    "def ols(X, Y):\n",
    "    return torch.linalg.lstsq(X, Y).solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ALIGN > 0:\n",
    "    if ALIGNMENT_MODEL == \"ridge\":\n",
    "            W_align = torch.load(f\"{model_dir}/align_ridge.pt\").cpu().T\n",
    "    elif ALIGNMENT_MODEL == \"distillation\":\n",
    "            W_align = torch.load(f\"{model_dir}/align_distillation.pt\").cpu().T\n",
    "else:\n",
    "    W_align = torch.eye(hidden_states.shape[1], device=hidden_states.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rand_proj_labels(prf_key, k):\n",
    "    rng = torch.Generator()\n",
    "    rng.manual_seed(prf_key)\n",
    "    W_random, _ = torch.linalg.qr(torch.randn(\n",
    "        W_align.shape[1], k, generator=rng))\n",
    "    W_random = W_align @ W_random\n",
    "    logits = F.linear(hidden_states, W_random.T)\n",
    "    all_labels = torch.argmax(logits, dim=1)\n",
    "    return all_labels\n",
    "\n",
    "\n",
    "def generate_kmeans_labels_new(prf_key, k):\n",
    "    hidden_states_aligned = torch.matmul(hidden_states, W_align)\n",
    "\n",
    "    if ALIGN > 0:\n",
    "        # Normalize for cosine distance\n",
    "        kmeans_input = torch.nn.functional.normalize(\n",
    "            hidden_states_aligned, dim=1)\n",
    "        # Inner product == cosine sim for normed vectors\n",
    "        index = faiss.IndexFlatIP(kmeans_input.shape[1])\n",
    "    else:\n",
    "        kmeans_input = hidden_states_aligned\n",
    "        index = faiss.IndexFlatL2(kmeans_input.shape[1])  # Euclidean\n",
    "\n",
    "    # Convert to float32 numpy\n",
    "    data_np = kmeans_input.cpu().numpy().astype('float32')\n",
    "\n",
    "    # Build kmeans object\n",
    "    kmeans = faiss.Clustering(\n",
    "        data_np.shape[1],\n",
    "        k\n",
    "    )\n",
    "    kmeans.niter = 200\n",
    "    kmeans.seed = prf_key\n",
    "    if ALIGN > 0:\n",
    "        kmeans.spherical = True\n",
    "\n",
    "    # Train and get labels\n",
    "    kmeans.train(data_np, index)\n",
    "    _, labels = index.search(data_np, 1)\n",
    "\n",
    "    all_labels = torch.tensor(\n",
    "        labels.squeeze(), device=hidden_states.device, dtype=torch.long)\n",
    "    centroids = torch.tensor(\n",
    "        faiss.vector_to_array(kmeans.centroids), device=hidden_states.device, dtype=torch.float32)\n",
    "    return all_labels, centroids\n",
    "\n",
    "\n",
    "\n",
    "def generate_kmeans_labels(prf_key, k):\n",
    "    kmeans = MiniBatchKMeans(\n",
    "        n_clusters=k, random_state=prf_key, batch_size=8192*10, max_iter=200)\n",
    "    hidden_states_aligned = torch.matmul(hidden_states, W_align)\n",
    "    # Normalize because cosine distance matters for for aligned vectors\n",
    "    hidden_states_aligned = torch.nn.functional.normalize(\n",
    "        hidden_states_aligned, dim=1)\n",
    "\n",
    "    kmeans.fit(hidden_states_aligned.cpu().numpy())\n",
    "    all_labels = kmeans.labels_\n",
    "    all_labels = torch.tensor(\n",
    "        all_labels, device=hidden_states.device, dtype=torch.long)\n",
    "    centroids = torch.tensor(\n",
    "        kmeans.cluster_centers_, device=hidden_states.device, dtype=torch.float32)\n",
    "    return all_labels, centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "\n",
    "def compare_label_stability(method, prf_key1, prf_key2):\n",
    "    labels1 = method(prf_key1, 16).cpu().numpy()\n",
    "    labels2 = method(prf_key2, 16).cpu().numpy()\n",
    "\n",
    "    ari = adjusted_rand_score(labels1, labels2)\n",
    "    nmi = normalized_mutual_info_score(labels1, labels2)\n",
    "\n",
    "    print(f\"{method.__name__} - ARI: {ari:.4f}, NMI: {nmi:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(all_labels, all_hidden_states, min_size=100):\n",
    "    \"\"\"\n",
    "    Removes small clusters and filters corresponding hidden states.\n",
    "    \n",
    "    Args:\n",
    "        all_labels (torch.LongTensor): Tensor of shape (N,) with cluster labels.\n",
    "        all_hidden_states (torch.Tensor): Tensor of shape (N, D), hidden states.\n",
    "        min_size (int): Minimum number of samples to keep a cluster.\n",
    "\n",
    "    Returns:\n",
    "        new_labels (torch.LongTensor): Reindexed cluster labels (contiguous).\n",
    "        new_hidden_states (torch.Tensor): Filtered hidden states.\n",
    "    \"\"\"\n",
    "    device = all_labels.device\n",
    "    max_label = all_labels.max().item()\n",
    "\n",
    "    # Count members in each cluster\n",
    "    label_counts = torch.bincount(all_labels, minlength=max_label + 1)\n",
    "\n",
    "    # Identify valid clusters\n",
    "    valid_mask = label_counts >= min_size\n",
    "    valid_labels = torch.nonzero(valid_mask).squeeze(1)\n",
    "\n",
    "    # Create remapping: old label → new label (contiguous), invalid → -1\n",
    "    mapping = -torch.ones(max_label + 1, dtype=torch.long, device=device)\n",
    "    mapping[valid_labels] = torch.arange(valid_labels.size(0), device=device)\n",
    "\n",
    "    # Remap all labels (invalid → -1)\n",
    "    remapped_labels = mapping[all_labels]\n",
    "\n",
    "    # Mask for valid entries\n",
    "    valid_idx = remapped_labels != -1\n",
    "    filtered_labels = remapped_labels[valid_idx]\n",
    "    filtered_hidden_states = all_hidden_states[valid_idx]\n",
    "\n",
    "    return filtered_labels, filtered_hidden_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PRF_KEY = PRF_KEY % 2**64\n",
    "if LABELING == \"kmeans\":\n",
    "    all_labels, centroids = generate_kmeans_labels(PRF_KEY, k)\n",
    "    all_labels, hidden_states = clean(all_labels, hidden_states, min_size=10)\n",
    "    k = all_labels.max().item() + 1\n",
    "    \n",
    "    print(f\"Reduced number of classes: {k}\")\n",
    "elif LABELING == \"rand_proj\":\n",
    "    all_labels = generate_rand_proj_labels(PRF_KEY, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot counts of each cluster as pie chart\n",
    "unique, counts = torch.unique(all_labels, return_counts=True)\n",
    "counts = counts.cpu().numpy()\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(counts, labels=unique.cpu().numpy(), autopct='%1.1f%%')\n",
    "plt.title(\"Cluster Distribution\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a dataset with the labels\n",
    "dataset = TensorDataset(hidden_states, all_labels)\n",
    "train_size = int(0.75 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_indices = train_dataset.indices\n",
    "val_indices = val_dataset.indices\n",
    "train_hidden_states = hidden_states[train_indices]\n",
    "train_labels = all_labels[train_indices]\n",
    "\n",
    "# create a downsampled dataset from the train dataset\n",
    "train_hidden_states_downsampled = []\n",
    "train_labels_downsampled = []\n",
    "for i in range(k):\n",
    "    class_indices = (train_labels == i).nonzero(as_tuple=True)[0]\n",
    "    class_data = train_hidden_states[class_indices]\n",
    "    # Sample min(samples_per_class, available samples)\n",
    "    sampled_indices = class_indices[torch.randperm(\n",
    "        len(class_data))[:min(30000, len(class_data))]]\n",
    "    train_hidden_states_downsampled.append(\n",
    "        hidden_states[sampled_indices])\n",
    "    train_labels_downsampled.append(all_labels[sampled_indices])\n",
    "train_hidden_states_downsampled = torch.cat(\n",
    "    train_hidden_states_downsampled)\n",
    "train_labels_downsampled = torch.cat(\n",
    "    train_labels_downsampled)\n",
    "\n",
    "\n",
    "val_hidden_states = hidden_states[val_indices]\n",
    "val_labels = all_labels[val_indices]\n",
    "\n",
    "\n",
    "print(f\"Train size: {train_size}, Val size: {val_size}\")\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128,\n",
    "                              shuffle=True, num_workers=1)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rescale(final_matrix, X_train_dataset, X_train_labels):\n",
    "    X_projected = F.linear(X_train_dataset, final_matrix)\n",
    "    max_values, max_indices = torch.max(X_projected, dim=1)\n",
    "    cluster_max_means = []\n",
    "    for i in range(k):\n",
    "        values = max_values[X_train_labels == i]\n",
    "        assert len(values) > 0, f\"Cluster {i} is empty\"\n",
    "        cluster_max_means.append(values.mean())\n",
    "\n",
    "    cluster_max_means = torch.tensor(\n",
    "        cluster_max_means, device=final_matrix.device).pow(-1)\n",
    "    cluster_max_means = torch.diag(cluster_max_means)\n",
    "    final_matrix = cluster_max_means @ final_matrix\n",
    "    return final_matrix\n",
    "\n",
    "\n",
    "def compute_accuracy(final_matrix, X, y_true):\n",
    "    X_projected = F.linear(X, final_matrix)\n",
    "    y_pred = torch.argmax(X_projected, dim=1)\n",
    "    accuracy = (y_pred == y_true).float().mean().item()\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def post_process(weights, projection):\n",
    "    selector_matrix = weights @ projection.T\n",
    "    final_matrix = rescale(\n",
    "        selector_matrix, train_hidden_states_downsampled, train_labels_downsampled)\n",
    "    train_accuracy = compute_accuracy(\n",
    "        final_matrix, train_hidden_states_downsampled, train_labels_downsampled)\n",
    "    val_accuracy = compute_accuracy(\n",
    "        final_matrix, val_hidden_states, val_labels)\n",
    "    print(\n",
    "        f\"Train Accuracy: {train_accuracy:.4f} Val Accuracy: {val_accuracy:.4f}\")\n",
    "    return final_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one hot encoding of train_labels\n",
    "train_labels_one_hot = torch.zeros(\n",
    "    train_labels.size(0), k)\n",
    "train_labels_one_hot.scatter_(1, train_labels.unsqueeze(1), 1)\n",
    "train_labels_one_hot = train_labels_one_hot.float()\n",
    "\n",
    "\n",
    "W = ridge_regression(\n",
    "    train_hidden_states @ W_align.cpu(), train_labels_one_hot, alpha=1e-3)\n",
    "\n",
    "# Assert that W does not have NaN values\n",
    "assert not torch.isnan(W).any(), \"W has NaN values\"\n",
    "\n",
    "final_matrix = post_process(W.T, W_align)\n",
    "\n",
    "assert not torch.isnan(final_matrix).any(), \"Post processed W has NaN values\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample_projected = F.linear(val_hidden_states, final_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate one-hot vectors from val_labels\n",
    "one_hot_labels = torch.zeros(\n",
    "    (val_labels.shape[0], k), device=val_labels.device)\n",
    "one_hot_labels.scatter_(1, val_labels.unsqueeze(1), 1)\n",
    "\n",
    "# Calculate the L1 loss with X_sample_projected and one_hot_labels\n",
    "loss = F.l1_loss(X_sample_projected, one_hot_labels)\n",
    "print(f\"Final L1 loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = (k + 1) // 2  # Ensure enough rows for all classes\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=2, figsize=(\n",
    "    12, 4 * rows), constrained_layout=True)\n",
    "axes = axes.flatten()  # Flatten in case of a single row\n",
    "l1_loss = nn.L1Loss()\n",
    "class_counts = torch.zeros(k)\n",
    "total_loss = 0\n",
    "for i in range(k):\n",
    "    class_indices_1 = (val_labels == i).nonzero(as_tuple=True)[0]\n",
    "    class_counts[i] = len(class_indices_1)\n",
    "    class_data = X_sample_projected[class_indices_1].cpu()\n",
    "    argmax = class_data[:, i]\n",
    "    rest = torch.cat(\n",
    "        [class_data[:, :i], class_data[:, i+1:]], dim=1)\n",
    "    rest = rest.sum(dim=1)\n",
    "\n",
    "    argmax_loss = l1_loss(argmax, torch.ones_like(argmax))\n",
    "    rest_loss = l1_loss(rest, torch.zeros_like(rest))\n",
    "    print(f\"Class {i} argmax loss: {argmax_loss}\")\n",
    "    print(f\"Class {i} rest loss: {rest_loss}\")\n",
    "    total_loss += argmax_loss + rest_loss\n",
    "    axes[i].hist(argmax, bins=100, alpha=0.5, label=f'Class {i} top')\n",
    "    axes[i].hist(rest, bins=100, alpha=0.5, label=f'Class {i} rest')\n",
    "\n",
    "    axes[i].set_xlabel(\"Value\")\n",
    "    axes[i].set_ylabel(\"Frequency\")\n",
    "    axes[i].set_title(f\"Values for Class {i}\")\n",
    "    axes[i].legend()\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(k, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average L1 loss: {total_loss/k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions = class_counts / class_counts.sum()\n",
    "plt.pie(proportions.numpy(), labels=range(k), autopct='%1.1f%%')\n",
    "plt.title('Cluster Proportions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_values, max_indices = torch.max(X_sample_projected, dim=1)\n",
    "for i in range(k):\n",
    "    values = max_values[val_labels == i].cpu()\n",
    "    # Handle empty clusters\n",
    "    if len(values) == 0:\n",
    "        continue\n",
    "    print(f\"Cluster {i}: {values.mean()}, {values.std()}\")\n",
    "    print(f\"Min: {values.min()}, Max: {values.max()}\")\n",
    "    plt.hist(values, bins=50,\n",
    "             alpha=0.5, label=f'Cluster {i}')\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Max Values\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "output_data = {\n",
    "    \"final_matrix\": final_matrix.cpu().numpy().tolist(),\n",
    "}\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(output_data, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
