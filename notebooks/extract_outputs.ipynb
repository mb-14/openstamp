{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Directory with JSON files\n",
    "input_dir = \"../output\"\n",
    "\n",
    "models = [\n",
    "    \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"mistralai/Mistral-7B-v0.3\",\n",
    "    \"cygu/llama-2-7b-logit-watermark-distill-kgw-k1-gamma0.25-delta2\"\n",
    "]\n",
    "\n",
    "\n",
    "output_csv = os.path.join(input_dir, \"metrics.csv\")\n",
    "\n",
    "filename_pattern = re.compile(\n",
    "    r\"output_.*?\"\n",
    "    r\"(?:align=(\\d+))?[^a-zA-Z0-9]*\"\n",
    "    r\"(?:dataset=([a-zA-Z0-9_\\-]+))?[^a-zA-Z0-9]*\"\n",
    "    r\"\\.json$\"\n",
    ")\n",
    "rows = []\n",
    "\n",
    "\n",
    "def parse_row(json_file):\n",
    "    with open(json_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        config = data[\"config\"]\n",
    "        metrics = data[\"metrics\"]\n",
    "        metrics_60 = data.get(\"metrics_dipper_text_lex60_order0\", {})\n",
    "        metrics_20 = data.get(\"metrics_dipper_text_lex20_order0\", {})\n",
    "        ppl = data.get(\"ppl\", {})\n",
    "        watermark = data[\"watermark\"]\n",
    "\n",
    "        if watermark == \"gaussmark\":\n",
    "            config_id = f\"watermark=gaussmark_sigma={config['sigma']}_param={config['target_param_name']}\"\n",
    "        elif watermark == \"mb\":\n",
    "            config_id = f\"align={align}_gamma={config['gamma']}_delta={config['delta']}_nclusters={config['n_clusters']}\"\n",
    "        elif watermark == \"mb2\":\n",
    "            config_id = f\"watermark=mb2_delta={config['delta']}\"\n",
    "        elif watermark == \"mb3\":\n",
    "            config_id = f\"watermark=mb3_delta={config['delta']}\"\n",
    "        elif watermark == \"distilled\":\n",
    "            config_id = f\"watermark=distilled\"\n",
    "\n",
    "        row = {\n",
    "            \"config_id\": config_id,\n",
    "            \"dataset\": dataset,\n",
    "            \"n_clusters\": config.get(\"n_clusters\"),\n",
    "            \"auroc\": metrics.get(\"auroc\"),\n",
    "            \"best_f1_score\": metrics.get(\"best_f1_score\"),\n",
    "            \"tpr_1_fpr\": metrics.get(\"tpr_1_fpr\"),\n",
    "            \"tpr_0.1_fpr\": metrics.get(\"tpr_0.1_fpr\"),\n",
    "            \"auroc_lex60\": metrics_60.get(\"auroc\"),\n",
    "            \"f1_lex60\": metrics_60.get(\"best_f1_score\"),\n",
    "            \"tpr1_lex60\": metrics_60.get(\"tpr_1_fpr\"),\n",
    "            \"auroc_lex20\": metrics_20.get(\"auroc\"),\n",
    "            \"f1_lex20\": metrics_20.get(\"best_f1_score\"),\n",
    "            \"tpr1_lex20\": metrics_20.get(\"tpr_1_fpr\"),\n",
    "            \"ppl_mean\": ppl.get(\"mean\"),\n",
    "            \"mean_seq_rep_3\": data.get(\"mean_seq_rep_3\"),\n",
    "            \"model\": model_suffix,\n",
    "        }\n",
    "        return row\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    model_suffix = model.split(\"/\")[-1]\n",
    "    model_dir = os.path.join(input_dir, model_suffix)\n",
    "    json_files = [f for f in os.listdir(model_dir) if f.endswith(\".json\")]\n",
    "    for json_file in json_files:\n",
    "        match = filename_pattern.match(json_file)\n",
    "        if not match:\n",
    "            continue\n",
    "\n",
    "        align = int(match.group(1)) if match.group(1) is not None else None\n",
    "        dataset = match.group(2) if match.group(2) is not None else None\n",
    "        filepath = os.path.join(model_dir, json_file)\n",
    "        try:\n",
    "            row = parse_row(filepath)\n",
    "            rows.append(row)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filepath}: {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Group by config_id and average all metric columns\n",
    "grouped_df = df.groupby([\"config_id\", \"dataset\", \"model\"]).mean(\n",
    "    numeric_only=True).reset_index()\n",
    "\n",
    "# Write to CSV\n",
    "grouped_df.to_csv(output_csv, index=False)\n",
    "print(f\"Saved grouped averages to: {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
